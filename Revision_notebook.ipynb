{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5636947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import IFrame\n",
    "import random\n",
    "from collections import Counter\n",
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5a538",
   "metadata": {},
   "source": [
    "# Shannon entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c434e15",
   "metadata": {},
   "source": [
    "\n",
    "This is the formula for entropy, where $H$ is the entropy measure and $X$ is a discrete probability distrbution:\n",
    "\n",
    "$$H(X) = -\\sum_{x \\in X} p(x)\\log_{2} p(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f20cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['cats', 'rats', 'bats']\n",
    "\n",
    "words_1 = random.choices(words, weights = (0.8, 0.1, 0.1), k = 100)\n",
    "words_2 = random.choices(words, weights = (0.5, 0.25, 0.25), k = 100)\n",
    "words_3 = random.choices(words, weights = (0.33, 0.33, 0.33), k = 100)\n",
    "\n",
    "dist_1 = [i/sum(Counter(words_1).values()) for i in Counter(words_1).values()]\n",
    "dist_2 = [i/sum(Counter(words_2).values()) for i in Counter(words_2).values()]\n",
    "dist_3 = [i/sum(Counter(words_3).values()) for i in Counter(words_3).values()]\n",
    "\n",
    "ent_1 = sp.stats.entropy(dist_1, base = 2) # Gets the entropy using log base 2 \n",
    "ent_2 = sp.stats.entropy(dist_2, base = 2)\n",
    "ent_3 = sp.stats.entropy(dist_3, base = 2)\n",
    "\n",
    "print(\"The entropy of dist_1 is {} bits.\".format(ent_1),\"The entropy of dist_2 is {} bits.\".format(ent_2), \"The entropy of dist_3 is {} bits.\".format(ent_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909f469",
   "metadata": {},
   "source": [
    "# Levenshtein edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb356a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.metrics import jaccard_distance\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11aff957",
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarian = ['aggodalom', 'apacs', 'széjjel', 'szét', 'apátia', 'aperitív', 'földtávol', 'guta', 'apostol', 'apparátus', \n",
    "'cuka', 'fellebbez', 'szózat', 'függelék', 'étvágy', 'taps', 'almalé']\n",
    "\n",
    "english = sample(words.words(), 17)\n",
    "\n",
    "all_words = hungarian + english\n",
    "\n",
    "distances = [] #Calculates edit distances\n",
    "\n",
    "for i in all_words:\n",
    "    dist = []\n",
    "    for j in all_words:\n",
    "        dist.append(edit_distance(i, j))\n",
    "    distances.append(dist)\n",
    "    \n",
    "df = pd.DataFrame(distances) # makes a dataframe from the distances\n",
    "df.columns = all_words\n",
    "df.index = all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f530b3",
   "metadata": {},
   "source": [
    "# Tokenising and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28a68b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punct = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45db6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"The quick brown fox jumped over the lazy dogs. The community of fowl sang in the dawn. The blind mice retreated before the feral felines. The geese flew north to escape the wolves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "371c5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(sent)\n",
    "lemmas = [lemmatizer.lemmatize(i) for i in words]\n",
    "lemmas = [i.lower() for i in lemmas if i not in punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0fefb2",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83eacdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebc3fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_g = {'topic':'love'}\n",
    "\n",
    "gut = 'https://gutendex.com/books/'\n",
    "\n",
    "rg = requests.get(url = gut, params = params_g)\n",
    "\n",
    "rg = rg.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9c6c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "links = []\n",
    "\n",
    "for i in range(len(rg['results'])):\n",
    "    try:\n",
    "        links.append(rg['results'][i]['formats']['text/plain'])\n",
    "        names.append(rg['results'][i]['title'])\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c190908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for i in links:\n",
    "    response = requests.get(i)\n",
    "    texts.append(response.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11588f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
